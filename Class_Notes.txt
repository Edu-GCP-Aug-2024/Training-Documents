Google Cloud Platform Certification Training Programme :

3rd Aug. 2024  - Orientation 	- 1Hr Session

LIVE Session starts from 10th Aug. 2024 

WeekEnds - 8:30PM - 11:30 PM IST Hrs

~~~~~~~~~~~~~~~~~~~~~~~
Day 1 | 10th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~

	Introduction to GCP
	
	Google Cloud Platform 
	
	Account Creation 
	
	
	Cloud Computing :::
	
		What is Cloud Computing ?
		
		Why we need ?
		
		Benefits ?
		
		Service Module ?
		
		Type of Cloud Computing Model ?
		
		Core Services ?
		
		
	On-Premises 
	
		- Owned and Managed by the user.
	
	Cloud Platform 
	
		- Managed by the Service Provider.
		
		
	Insurance Domain --> 60 Years 
	On-Premises --> Monolith Application Architecture. - Legacy
	IT Services 
	
	Cloud Migration!
	
	
	
	Hybrid Model :
		public & Private 
		Cloud and On-Premises
		
	Cloud Platform -- 10 Years --> AWS 
	
	Azure / GCP(SAAS)
	
	Hybrid & Multi-Cloud Platform 
	
	Process Automation - to keep the data in-sync with all the platform
	
	DevOps !
	
	Application/Legacy Modernization:::
	
	
	Create a Free Account on Google Cloud
	
		https://cloud.google.com/
	
		- Active Mobile Number 
		- Active Email ID
		- Valid Credit/Debit card - Authentication purpose.
				- Ensure that, the card is eligible for international transaction
	
	Login to that account!
	
	

~~~~~~~~~~~~~~~~~~~~~~~
Day 2 | 11th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~
	
	https://cloud.google.com/
	
	Manage Google Cloud
	
	Access - Account with Google Cloud Platform 
		
	GC Console to explore the GC Services 
	
	Various methods to interact with GC Services
	
	
	
	
	Understanding the Infra-Structure 
	
	Cloud Platform :::
	
	Why Cloud Platform ?
	
		Launch a Website -> Web Application ->
		
		Resources! 
		
		Linux Machine --> Cloud Account -- GCP/AWS/Azure --> Linux Based VM
			-
			
		Online Training! --> LMS - Web Application 
		
		
		
		Dev the Web Application
		
		Build the Application
		
		Test the Application 
		
		Deploy to Production (Web Application(Target))
		
		Huge set of resources :
		
		Infra-Structure - Environments:
		
		Non-Prod Environments													Production Environments
		
			Dev Environment
			
			Build Environment
			
			Test Environments
			
				QA Environment
				UAT Environment		---> Staging/Pre-Prod Environment		---> 	Production Servers
				
				
		On-Premises Environments - requires a huge upfront investment 
		
		
		- GCP -->
		
		
		www.google.com :
		
			gmail service 
			Google drive 
			Maps 
			translate 
		
		
		
		Enterprise Level Account 	==> Root level Account --> Billing will be mapped with root account
		
			Organization  (AD) 
				Project1 	
					Resources(Compute/Storage/DataBase/Networking)
				Project2 - developers  
					Resources(Compute/Storage/DataBase/Networking)

			Organization  (Test) 
				Project1 	
					Resources(Compute/Storage/DataBase/Networking)
				Project2 - 
					Resources(Compute/Storage/DataBase/Networking)
					
			RBAC - Role Based Access Control 
			
			
			
			Infra-Structure Management 
			
				Dev
				
				Testing 
				
				Process Automation 
				
				AD 
				
					Java
					.Net
					Python 
		
		Web Application --> E_Commerce portal! www.loksaieta.com
		
		===> Web-Application/Mobile/Desktop/Embedded Application
		
		Micro-Service Based Application Architecture :::
		
		www.amazon.com   1000s of micro-services 
		
			lakhs of use cases and test scenarios 
		
		Functions :
		
		sign-up			--> Micro-Service1	-> Developer - Independently Designed/developed/Tested/Implemented to Prod.
		sign-in			--> Micro-Service2 
		search 
		add to cart 
		place the order 
		make payment 
		confirm
		track 
		
		
		Containerized Application
		
			mywebapp-sign-in.war 
			
				Application Image 
				
				mywebapp-sign-in-img:v1.0
				
				
		
		3 tier application :
		
			Front-End Layer 		--> Test 
			
			Application Layer 
			
			DataBase 
		
		End-Customers!
		
			Laptops / Mobile / Tabs /		===> Hardware device
			
			Laptop --> windows/Mac/Linux 	===> Platform 
			
						Chrome/Edge/Firefox
		
		
		VM 
		
		GCP ::: https://console.cloud.google.com/
		
		
		
		External Storage :
		
			Persistant Volumes 
		
		
	
	Various methods to interact with GC Services
		
		- GC Console to explore the GC Services 

		- GCloud Shell -- Through Web Browser 		
			gcloud cli commands to access the resource 
	
		- gcloud API Services 
		
		- gcloud sdk - software development kit 
		
		- IAC Tools - Infra-Structure As Code -> 
				- Terraform 
	
	https://cloud.google.com/sdk/docs/cheatsheet
	
	
	
		Non-Prod Environments													Production Environments
		
			Dev Environment	
				- Coding - Development Tools - GitHub 
			
			Build Environment
				- Application Build:
					- It is a process of compiling the source code & Create Artifacts
					
			
			Test Environments
			
				QA Environment		Artifacts
				UAT Environment		---> Staging/Pre-Prod Environment		---> 	Production Servers

		Deployment Package : *Artifacts 
		
			Application Should be Containerized!
			
			Containerization :
			
				- Is a process of Package the application(*artifacts) with all its dependencies
				
				Container Engine 
				
					Create Container Images 
					
					Create Containers 
					
				Kubernetes is a Container Orchestration Tool : Used deploy the Containerized Applications
					- Auto-scaling --> scale-up/down 
					- Load-Balancing 
					- Self Healing 
					
					20 Prod Servers! +++
					
				www.amazon.com 
				
				online reservation system 
				
					10000 users to access this application
					
					50000 users spike!
					
		
		
		github account ?

~~~~~~~~~~~~~~~~~~~~~~~
Day 3 | 17th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~


	Virtual Machines :::
	
		- Virtual Machines are called as Hardware level virtualization.
		- VMs are used to run the Operating System
		- On top of ths operating system, Applications can be up and running.
		- Even if there is not Application, VM will still be running.
		
	Linux Operating System :::
	
		- Open-Source OS and It is reliable, Secured 
		
		Linux Distributions :::
	
			- Various Flavors of Linux :
			
				Package Manager :::
				
				Debian/Ubuntu			apt / apt-get		
				
				RHEL/Centos				yum 
				
				Fedora 					dnf
			
				
	- Created a VM	
	
	
		Regions :::: Geographical Location
			- Availability Zones (2-3 ==> DataCenter)
					- Data Center is a collection of Servers 
		
		
			
		Non-Prod Environments 											Production Environments
		
		Dev
		Build 
		
		Test (Can be created, testing, Destroy)
			QA
			UAT 															Prod Servers (Running 24/7)
		
		
		IAC Tools - Terraform / Ansible 
		
		Infra-Structure As Code ---> 
		
		
		CI/CD :::
		
		
		SCM_Checkout --> Build --> Deploy to QA_Server --> Automated QA_Testing 
		
		
		SCM_Checkout --> Build --> Create QA_Server(Terraform) --> Configure QA_Server(Ansible) --> Deploy to QA_Server --> Automated QA_Testing
		
																																	|
																																	|
																															Notify the User 
																																	|
																																	|
																															Destroy 	QA_Server(Terraform)
																															
		Build Orchestration Tools :
		
			Jenkins 			--> groovy Scripts 
			Azure Pipelines 	--> *.yaml
			AWS CodePipeline 	--> *.yaml
			Gitlab-ci 			--> *.yaml
			
			
							
~~~~~~~~~~~~~~~~~~~~~~~
Day 4 | 18th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~	
		
	Compute Service 
	
		- Create Virtual Machines!
		
		Console 
		
		Gcloud Shell
		
		gcloud sdk ==> to manage the gcloud resources 
		
		
		https://cloud.google.com/sdk/docs/cheatsheet
		
		
		gcloud sdk ==> to manage the gcloud resources 
		
		Working with GCloud sdk :::
		
			- Install gcloud sdk - in the local machine (Windows)
			
			
		
		gcloud compute instances list:
		
		
		gcloud compute instances create sainstance91--zone asia-south2-a
		
		
	VM - 
	
		Production Deployment :::
		
			Deploy the Application with ZERO Downtime ????
			
			
	Virtual Machines :::
	
		- Virtual Machines are called as Hardware level virtualization.
		- VMs are created using Hypervisor 
		- VMs are used to run the Operating System
		- On top of ths operating system, Applications can be up and running.
		- Even if there is not Application, VM will still be running.
	
	
	Containers ::::

		- Containers are called as OS Level Virtualization.
		- Containers are created using Container Engine 
		- Containers are Not used to run the Operating System
		- Conaintainer are used to run the task/applcation.
		- If there is no task, Container will immediately goto exit state.
		
		
	Containerization ::::
		
		- It is process of packaging the applications along with its dependencies
		
		
	Monolith Application Architecture :::
	
		- Application is tightly coupled.
		- It is not easy to split and deploy any function independently 
		
		- Only Continuous Delivery can be possible with the Monolith Application Architecture
		
	Micro-Service Based Application Architecture ::
	
		- Application is loosely coupled.
		- The functions/Modules are called as microservice 
		- Each Micro-Service can be independently created, test, and deployed to prod, without any manual intervension
		
		- Continuous Deployment can be possible with the Micro-Service Based Application Architecture
.		
		
		
	Containers can be used at two levels :
	
	Environments :
	
	Non-Prod 
	
		Dev Environment		- coding and development 
		
		Build Environment	- Compile the source code, create artifacts(Binaries - *.war/*.jar)
							
							Deploy the artifacts(myapp.war) from Build Environment to QA Environment
							
							Tools : jdk 11, tomcat server 8.5
							
								Create Container Package --> Is composed of (myapp.war / jedk 11, toncat server 9.5)
														 --> Is Composed myapp-pkg1
							
								This Package myapp-pkg2
								
								
		Test Environments 
			QA 				--> myapp.war								myapp-pkg2:v1.0
								Tools : jdk 11, tomcat server 8.5
								Tools : jdk 8, tomcat server 10
								
			UAT 
								Tools : jdk 11, tomcat server 8.5		myapp-pkg2
								Tools : jdk 8, tomcat server 10
	Prod 
	
		Prod Environments
		
		
	Deployment Perspective :::
	
		Application Build :::
		
			
			
		Application Test :::
		
		
		Application Release :::
	
	
		Terminologies ::
		
			- Container Engine 
			 
			- Containerization of Application using Micro-Service Based Application Artifacts.
			
			- Container Images 
					---> It is a static file, defines the various levels of Instructions to development the application
						 This cannot be executed.
						 
						 
					
			- Container 	
					---> 	Used to run the image 
							Used to manage the application and tomcat severs in the above  example 
			
			- Container Registry 
			
					---> Used to store the container images 
						 Dockerhub
						 
						 https://hub.docker.com/
			
			- Repository 
			
					---> Subset of Container Registry.
					
			- Trouble Shooting Issues :
			
			
			- Kubernetes_Cluster 
					- WorkerNode1
					- WorkerNode1 -Install any applcation and run as pod 
					
					
			- POD 
				- Pods are somallast unit of task taht run on taret environment
			
		How to Create an Application :
		
			Micro-Service based applcation
			
			Create Application Build 
			
			Create Application Service Image 
			
			Deploy to Kubernetes - GKE 
			
			
			
			
			Architecture of Kubernetes :::
			
			
			Dockerhub :::
			
			

~~~~~~~~~~~~~~~~~~~~~~~
Day 5 | 24th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~			
			
		
	Application Builds & Deployments :::
	
		Dev Envi 
		
		Build Environment 
		
		Test Environment
		
			QA 
			
			UAT 

		Production Environment
		
		
		Working with Container 
		
		Docker Container Engine :::
		
			- Docker Cli Command 
			
			
		Install Docker :
		
			sudo apt install docker.io -y 		# 
		
		GCloud Shell ==> VMs
		
		Launch a VM ::
		
		Start-Up Task!
		
		
		Docker CLI Commands :::
		
			docker images			# Used to get the list of Container Images 
			
			docker ps 				# used to get the list of running containers 
			
			docker ps -a			# Used to get the list of all containers 
			
			
			docker pull <image_name # Download an image from container registry
			
			docker run <image_name>	# Used to create Container
			
			Modes of Execution :
			
				- Foreground/Attached Mode 						# Default 				
					docker run centos sleep 20 
				
				- Background Mode 				
					docker run -d sleep 20
					
				- Interactive Mode			
					docker run -it centos bash 
					
			
			Micro_Service : mywebapplogin_svc1:v1.0
			
				- 3 Tier Application
				
				Front-End Layer 
				
				Application Layer
				
				Back_End/Dbase 
		
		
			docker stop <container_id>		# Stop the running container
			
			docker start <container_id>		# Start the existing container 			
			
			docker exec -it <container_id> bash					# Used to Login to Running Container 
			
			
			Container Port Mapping :::
			
				docker run -it tomcat:8.0 bash 

				docker run -it tomcat:8.0
				
				
				docker run -it -p 8088:8080 tomcat:8.0 bash 
				
				-p <host_port>:<container_port>
				
				<external_ip_addrs>:8088 	==> to access the application 
				
				
			Container Volumes :::
			
				Stateless Application :::
				
					
				Stateful Application :::
				
				
				Persistant Volume.
				
				
				docker volume list 
				docker volume create edu-gcp-vol1
				docker volume inspect edu-gcp-vol1
				
			How to Create Container Images ::
			
				Docker Commit ::
				
					- It is used to create a container Image based on the existing container reference
					
					Syntax: 
					
					docker commit <container_id> <repository_name>/<New_Image_Name>:<tag>
					
					Eg.: 
					
					docker commit a2e7b4e44913 loksaieta/gcp-img1:v1.0
				
				
				Docker Build ::
				
					It used to Create/Build a container image from the scratch using Dockerfile 
					
					vi Dockerfile 
					
					FROM ubuntu 
					RUN apt update -y 
					RUN apt install git -y 
					RUN apt install maven -y 
					
					docker build -t loksaieta/gcp-test-img1 .			# the '.' at end, denotes te Dockerfile references
				
				
			
			Publish Docker Container Image to Container Registry ::
			
				- dockerhub
				
				- Login to DockerHub 
					- Goto User Account Settings
						- Choose Security tab
							- Select Personal Access token
								- Click on Generate New Token
								
								docker login -u loksasdasa
								
								d--tO8
			
								docker push <repository_name>/<New_Image_Name>:<tag>
			Remove/Delete Container 
			
				docker rm <container_id> 
				
				docker rm 25e9cdd128df 565fe4d29d16 d4869b4af043
				
			Remove/Delete Container Iamge ::
			
				docker rmi <image_name>
				
				docker rmi 
			
		
    1  apt update -y
    2  docker -version
    3  clear
    4  docker --version
    5  docker version
    6  docker images
    7  docker ps
    8  docker ps -a
    9  docker rmi centos
   10  celar
   11  clear
   12  docker images 
   13  docker ps 
   14  docker ps -a
   15  docker pull centos
   16  docker images 
   17  clear
   18  docker ps -a
   19  docker ps
   20  docker images 
   21  docker run centos
   22  docker ps
   23  docker ps -a
   24  docker run centos
   25  docker ps -a
   26  docker ps
   27  docker run centos sleep 20 
   28  docker ps
   29  docker ps -a
   30  clear
   31  docker ps
   32  docker ps
   33  docker run centos sleep 30
   34  docker ps
   35  docker run -d centos sleep 30
   36  docker ps
   37  docker ps -a
   38  docker run centos
   39  docker ps -a
   40  docker ps
   41  clear
   42  clear
   43  docker ps
   44  docker run -it centos bash
   45  docker images
   46  clear
   47  docker images
   48  docker run ubuntu
   49  docker images
   50  docker ps
   51  docker ps -a
   52  docker images
   53  docker ps
   54  docker ps 565fe4d29d16
   55  docker stop 565fe4d29d16
   56  docker run centos sleep 60
   57  docker run -it ubuntu bash
   58  docker ps
   59  docker ps -a
   60  docker start 25e9cdd128df
   61  docker ps
   62  docker ps
   63  docker exec -it 25e9cd
   64  docker exec -it 25e9cd bash
   65  docker ps -a
   66  docker ps
   67  docker stop 25e9cdd128df
   68  docker run -it tomcat:8.0 bash
   69  docker ps
   70  docker ps -a
   71  docker run -it tomcat:8.0 bash
   72  docker ps
   73  docker ps
   74  clear
   75  docker ps
   76  docker ps
   77  docker stop 4e7d1d 7ffefff
   78  docker ps
   79  docker volume list
   80  docker volume create edu-gcp-vol1
   81  docker volume inspect edu-gcp-vol1 
   82  cd /var/lib/docker/volumes
   83  ls
   84  cd edu-gcp-vol1/
   85  ls
   86  cd _data/
   87  ls
   88  pwd
   89  ls
   90  cat Containerdata.txt 
   91  pwd
   92  echo "rec1" >> infile1.txt
   93  ls
   94  echo "Rec" >> asdf.txt
   95  ls
   96  clear
   97  docker ps
   98  cd ~
   99  mkdir docker-contents
  100  cd docker-contents/
  101  vi Dockerfile
  102  ls
  103  cat Dockerfile 
  104  docker build -t loksaieta/gcp-test-img1 .
  105  docker images
  106  clera
  107  clear
  108  docker images
  109  docker login -u loksaieta
  110  docker push loksaieta/gcp-img1
  111  docker push loksaieta/gcp-img1:v1.0
  112  docker ps -a
  113  docker images
  114  docker rm 25e9cdd128df 565fe4d29d16 d4869b4af043
  115  docker ps -a
  116  clear
  117  docker images
  118  docker rmi loksaieta/gcp-test-img1
  119  docker images
  120  docker rmi loksaieta/gcp-img1:v1.0
  121  docker ps -a
  122  docker rmi ubuntu
  123  docker rm 31abecf14052
  124  docker stop 31abecf14052
  125  docker rmi ubuntu
  126  docker rmi -f loksaieta/gcp-img1:v1.0
  127  docker ps -a
  128  docker inspect df482da5201c
  129  clear
  130  history				



~~~~~~~~~~~~~~~~~~~~~~~
Day 6 | 25th Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~			
	
GKE ::::
		
	Deployments :::
	
	Micro-Service Based Applications 
	
	DevOps :::
	
	What is DevOps ????
	
	Jenkins
	Github 
	Jira
	
	Software Development Strategy :
	
	DevOps :::
	
	SDLC - Software Development Life Cycle ::::
	
	
		- Desktop Applications
		 
		- Mobile Applications 
		
		- Web Applications 
		
		- Embedded Applications 
		
	DevOps ???
	
	Typical SDLC Process :::
		
		Requirement Analysis 
		
		Design/Document 
		
		Code/Development 
		
		Testing 
		
		Implementation 
		
		Maintain/Monitor 
		
	Waterfall Model to this process :
		- Top-Down Approach
		- Execution will be in Linear Fashion
		
		
		Desktop Application --> 
		
				--> Super_Market Billing System 
						Functions/Module 
							- User Interface 
							- Stock 
							- Billing 
							- Payment 
								CASH Mode 
								CARD Mode 		+ UPI Mode + Online Payment Mode 
							- Generate Bills 
							
							
				
		Core Project :
		
			Requirement Analysis 		12 Months 		
			Design/Document 		
			Code/Development			7th Month 
			Testing 		
			Implementation 		
			Maintain/Monitor 		
			
		Enhancement Project :
		
			Requirement Analysis 			+ UPI Mode + Online Payment Mode  6 -7 months
			Design/Document 		
			Code/Development			
			Testing 		
			Implementation 		
			Maintain/Monitor 	

	AGILE Methodologies :::
	
				--> Super_Market Billing System 
						Functions/Module  			===> Iterations 
							- User Interface 
							- Stock 
							- Billing 
							- Payment 
								CASH Mode 
								CARD Mode 		+ UPI Mode + Online Payment Mode 
							- Generate Bills 		
	
		Iteration 1 : User Interface 
		
			Requirement Analysis
			Design/Document 	
			Code/Development	
			Testing 		
			Implemented to prod with proper approval 	
		
		
		Iteration 2 : Stock 
		
			Requirement Analysis
			Design/Document 	
			Code/Development	
			Testing 		
			Implemented to prod with proper approval 	
		
		Iteration 3 : Payment CASH Mode
		
			Requirement Analysis
			Design/Document 	
			Code/Development	
			Testing 		
			Implemented to prod with proper approval 	
		
		Iteration nth : Online Payment Mode 

			Requirement Analysis
			Design/Document 	
			Code/Development	
			Testing 		
			Implemented to prod with proper approval 
			
		
			Using AGILE Methodologies ;
			
			We can Achieve :
			
				- Continuous Development 
				
				- Continuous Integration 
				
				- Continuous Testing 
				
				- Continuous Delivery 
					- It expects manual approvals for Production release 
					- This might leads to down-time during Production release
				
				
			We canno Achieve :
			
				- Continuous Deployment
					- It never expect manual approvals for Production release 
					- Production releases can be done automatically without any manual intevension
					- This helps do Production releases without any downtime				

				
	DevOps :::
	
		DevOps is a Software Development Strategy which helps to promote the collaboration between the teams like Application Development Team  and Operations Team to achieve Continuous Development, Continuous Integration, Continuous Testing, Continuous Delivery, Continuous Deployment and Continuous Monitoring in  more automate fashion.
		
		
	Implement DevOps :::
	
		DevOps Team: 
			Infra-Structure Management Team
			Application Development Team 
			Testing Team 
			Release Management Team 
			Production Support Team
			Production Monitoring Team 
			IT Security Team 
			
			
		How the Application is developed, Tested , Deployed ::::
		
		DevOps Stages ::
		
			Continuous Development :::
			
				- Improve Developers' productivity
				
				
				Developer Role :
				
					Create Source Code :
					
					Save the Source Change to the Source Code Repository - github
					
				Using DevOps Strategy :
				
					Automate :
					
						Application Build 
							- Compile the code, Create Artifacts(Binaries - *.war/*.jar)
							- Unit Testing 
							
						Build Application Image using Docker 
							- Create App_img:v1.0
							- Publish App_img:v1.0 to Container Registry 
							
							
							
						Testing 
							QA 	Deploy  App_img:v1.0 using Kubernetes
							UAT Deploy  App_img:v1.0 using Kubernetes
						
						Prod Deploy  App_img:v1.0 using Kubernetes 
						
						Notifications 
						
						
				CI/CD Pipeline :::
				
				
		Jenkins :
		
			- Is a build orchestration tool 
			- Automate Application Builds and Deployments 
				
			- Jenkins using Master - Slave Architecture
			
			Jenkins_Master Node ::	Create Jenkins CI/CD Pipeline Projects 
			
				Jenkins_Slave Node :: Perform the applcation builds 
				
				
			Micro-Service Based Application Architecture ::
				- Containerized Deployments using Kubernetes 
			
		Container Orchestration Tools :::
		
		  - It is used to orchestrate the containers 
		  - It ensure high availability of containers
		
		
		deploy a service :
		
			User_Login_Service 
			
				Front-End 		C1
				
				Application 	C2
				
				Back_End/Dbase  C3
				
			Docker Compose ::
			
				- Is used to Execute Multiple Containers  as a Service.
				- Service Definition file - *.yaml 
				
			Docker Swarm ::

				User_Login_Service 
			
					Front-End 		C1 => 3 instance of C1
				
					Application 	C2
				
					Back_End/Dbase  C3

				
				- It is used to create replicas of containers to ensure high availability 
				- It can be used only for Docker Container
				- Scale-up / scale-down 
				- We cannot perform Auto-scaling / Load-Balancing
				- Cannot perform self-healing 
				
				Web Application :
				
					5000 users can access simultaneously 	===> 10 Instance of Containers 
					
					
			Kubernetes :::
			
				- Open-Source Kubernetes
				- It is used to create replicas of containers to ensure high availability 
				- It can be used only for any Container
				- Scale-up / scale-down 
				- Perform Deployments without any  downtime 
				- We can perform Auto-scaling / Load-Balancing
				- Can perform self-healing

			Managed Services :::
			
				AWS 	-> ECS/ECR/EKS
				Azure 	-> ACS/ACR,AKS
				GCP 	-> GCE/GCR/GKE 
			
		
		
	Working with Kubernetes ::
	
		Kubernetes Architecture
		
			- API Servers
			- ETCD 
			- Scheduler
			- Controller Manager 
			
			- Kubelet
			- Kube-Proxy 
			- CRI - COntainer Runtime Interface (Container-D)
			
			
		Kubernetes Terminologies/Concepts 
		
			Kubernetes Master
			
			Kubernetes Cluster 	- Is a collection of workernodes
			
				Kubernetes WorkerNode1,2,3,4,5,6
				
			Kubectl		--> Command Line Utility used to interact with Kubernetes
			
			kubelet 	--> Is a Kubernetes Agent runs on all the node. Responsible for Pods Deployments 
			
			kubeadm 	--> Is a Command Line Utility used to install and manage the kubernetes cluster 
			
			Pods 		--> Atomic Unit of Scheduling
			
			Controller Objects
			
				- Replication Controller 
				- Replicaset 
				- Daemonset 
				- Deployment Object 
				
			Services :
				- NodePort Services 
				- ClusterIP
				- Load Balancer
				
				
	Create Micro-Service Based Application :
	
	- Install Jenkins 
	- Configure Jenkins 
	- Setup build and deployments 
	- Integrate Kubernetes Cluster to Jenkins
	- Create end-to-end Deployment - CICD Pipeline 		
	- GKE
			
			
	
		
~~~~~~~~~~~~~~~~~~~~~~~
Day 7 | 31st Aug. 2024
~~~~~~~~~~~~~~~~~~~~~~~		

	Working with Kubernetes :::
	
	GKE - Google Kubernetes Engine!
	
	Kubernetes Cluster and Deploy pods
	It is used to create replicas of containers to ensure high availability 
	
	
	
	GKE :::
	
		Kubernetes can be installed and Configured by the User using standared approach
		
		in GKS : kubernetes cluster will be create 
		
			- Standard Approach
			- AutoPilot
			
			
	Kubectl :::
	
		It is a Command Line Utility Used to interact with Kubernetes control plane
		
		Perform Deployment :::
		
		
		Manifest File --> 
		
			Kubectl :::
			
		kubectl get nodes
		
		kubectl get ns 
		
		kubectl get pods --all-namespaces 
		
		kubectl get svc 
		
		kubectl get pods -o wide
		
	Namespace :::
			
		- Is a Logical Partitioning of Kubernetes Cluster 	
		
		Default Namespace 
		
		Dev Team 	Environment 
		
		Testing Team 	Environments
		
		
		c: folder1
		
			file1 --> 500KB
			
			
	
	It is used to create replicas of containers to ensure high availability 	
	
	
		Kubernetes Controller Manager :
		
			Replication Control Ojbect 
			ReplicaSet Object 
			Daemonset 
			Deployment 
		
		
			Replication Control & ReplicaSet :::
				Both are used to Create some replicas of Pods
				
				Replication_Controller --> Create replicas of pods and stored in the masternode config
											It used the Equality based operator
											It scale-up / scale-down
											
											envi = "dev"
											
											enii = "qa"
											
				Replicaset 				---> Used to create replicas of Pods		
											It used the Set based operator
											
											
											
											
				Daemonset 				---> Used to Deploy copy of pods in all the nodes / subset 
				
				
				Deployment 				---> 
											Is used to Deploy the containerised workloads in kubernetes
											It can perform, New deployments,
											Existing Application Upgrade / Downgrade 
											Rollback 
											Scale-up/Scale-down
											
											All these things can be achieved without any downtime. 
											
				
					- Uses the RollingUpdate Deployment Strategy :
					
					
					pod1 		-- v1.0				===> Upgrade to v2.0
					pod2 		-- v1.0
					pod3 		-- v1.0	- deleted once now instance is created 
					
					pod4		--> v2.0
					
					
				Automation of CICD Pipeline :::
				
				
~~~~~~~~~~~~~~~~~~~~~~~
Day 8 | 1st Sep. 2024
~~~~~~~~~~~~~~~~~~~~~~~	


	kubectl exec ?
	
	Working with pods 
	
	
	Create Pod 
	
	Login to Pod 
	
	Port Mapping --> 
	
	NodePort Service :::
	
	- NodePort Ranges between 30000 to 32767 
		
			Kubernetes_Master 
				Kubernetes_Cluster 
					Kubernetes WorkerNode1
					Kubernetes WOrkerNode2
					Kubernetes WorkerNode3
					
					
	Pod Deployment ::::
	
		- Create pod 
			1. Manifest file - nginx_pod.yaml

			
		- Login to the pod 
			2. kubectl create -f nginx_pod.yaml
			
	
	Replication_Controller ::
	
				Replication_Controller --> Create replicas of pods and stored in the masternode config
									It used the Equality based operator
									It scale-up / scale-down
									
				
				Deployment 				---> 
											Is used to Deploy the containerised workloads in kubernetes
											It can perform, New deployments,
											Existing Application Upgrade / Downgrade 
											Rollback 
											Scale-up/Scale-down
											It will automatically creates the Replicaset 
											
											All these things can be achieved without any downtime. 
											
				
					- Uses the RollingUpdate Deployment Strategy :											
					
		Daemonset 				
				---> Used to Deploy a copy of pod in all the nodes / subset 
				---> 
				
					KMaster
						KNode1,2,3,4,5,6
						
						
					- Monitor te node and app_confgig 
					
					- Logger Tool 
					
					
					
		Services ::::
		
			NodePort 
			
			ClusterIP
			
			Load Balancer
			
			
			
		Volumes ::::
		
		Containers --> Volumes

			Persistant Volumes :::
			
			
			Kubernetes Volumes :::
				- Emptydir 			# Default volume 
				- HostPath Volume	# No issues 
				- Persistant Volume 
				- Prsistable Volume Claim
				
				
	Data Security :::
	
		Security Vaults ===? 
		
		Appln. 
		Create query to database 
		
		
		Create Pipeline Projects 
				
				
				- ConfigMaps 
					- Used to maintain no-sensitive data 
				- Secrets
					- Used to Maintainer the Sensitive Data 
					- These data are accessible with in pods
		
		
		
					
			
~~~~~~~~~~~~~~~~~~~~~~~
Day 9 | 7th Sep. 2024
~~~~~~~~~~~~~~~~~~~~~~~	



		Services ::::
		
			NodePort 
			
			ClusterIP
			
			Load Balancer

	NodePort Service :::
	
	- NodePort Ranges between 30000 to 32767 


	Node Port Service - is for single service 
	
	Node Port 		==> Created at the Service Level.
	
	Load Balancer	==> Created at the applcation level.
	
	
	Ingress Rules/Protocols :::
	
		- It is used to route the request to the corresponding Services.
		
		- Simple Route 
				--> DNS Routing!
		
		- Host Based Routing 
			
		- Path Based Routing 
	
	
	www.google.com 
		- Maps 
		- Drive 
		- Translate 
		- .......
	

	- Host Based Routing 
	
		www.google.com 
	
			www.drive.google.com 
			www.translate.google.com 
			www.mail.google.com 
			www.maps.google.com 
		

	- Path Based Routing 
		
		www.gmail.com
		
			inbox 		===>	www.gmail.com/inbox 
			sent 		===> 	www.gmail.com/sent 
			trash 
		
		
		
	
	
	
	www.gmail.com 
	
	
	Security:::
	
		NameSpaces ::::
		
			- Is a logical partitioning of Kubernetes Cluster
	
	
			kubectl create namespace <dev>
			kubectl create namespace <qa>
	
# nginx-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  namespace: dev
  labels:
    app: nginx
    tier: dev
spec:
  containers:
  - name: nginx-container
    image: nginx

    ports:
    - containerPort: 80	
	
	
	Non-Prod Kube_Cluster ::

			Kubernetes_Master
				Kubernetes_WorkerNode1,2,3,4,5,6

	
		DEV_NameSpace 
		QA_NameSpace 
		App1_Dev_Namespace 
		App1_QA_NameSpace 


	Namespace are also used on Prod_ Kube_Cluster :::
	

		Kubernetes_Master
			Kubernetes_WorkerNode1,2,3,4,5,6


		Blue-Green Deployment :::


			Production Environment :::
																							
				Production_Servers(Deployment_Group - 5 Server) LIVE Environment 	===> 	webapp_V1.0
																							webapp_V1.1		# Minor Changes
																							webapp_V1.2		# Minor Changes
																							webapp_V1.3		# Minor Changes
																							
				Major Release :::
				
				webapp_V1.3			====> webapp_V2.0	
				
				
				Create Replica of Production Environment :::

				
					Production_Servers(Deployment_Group - 5 Server) ACTIVE Environment		Blue / Green Deployment
					
						Copy/Replicate the Production_Servers
						
						
							Production_Servers(Deployment_Group - 5 Server) 		# PASSIVE Environment
				
								Deploy the latest version *2.0 to this new Production_Servers
								
								
								
								
				Using Kubernetes :::
				
					Kubernetes_Master
						Kubernetes_WorkerNode1,2,3,4,5,6
						
					Create a Manifest file :::
					
						- To define the properties of Containers Deployments, Pods

					Prod_Environment ::
					
					Kubernetes_Master
						Kubernetes_WorkerNode1,2,3,4,5(Prod Servers)		
						
						
						BLUE-GREEN Deployment :::		Approve to run multiple jobs
						
						
							Current_Namespace ::
							
							NameSpace ::	LIVE-Prod Namespace 		myweb1(V1.0)		--> Active Server
							
							
							
								

							Prod Related ::
							
							NameSpace ::	New-Gen_App_Namespace  		myweb1.war(V2.0)		--> Just a Passive Server 
							ACTIVE 
							
							
							
			
		
~~~~~~~~~~~~~~~~~~~~~~~
Day 10 | 8th Sep. 2024
~~~~~~~~~~~~~~~~~~~~~~~								
					
	GKE - Kubernetes Security 
		
		Kubernetes uses RBAC ::

			API Server 
			
			
			User Authentication & Authorization 
			
			RBAC - Role based Access Control.
			
	GCloud Storage :

			
		RBAC - Role based Access Control.	
		
		
	Kubernetes Developer 
	
	Kubernetes Admininstration 
	
	Kubernetes Security Administration
		
		
	GCloud Storage :
	
		Storage Service

		Create VM
		And ceate sql db service
		Attach SQL Databse(VM)
		
		
					GCP Cloud Storage Bucket
						- Create storge bucket using Console 
						- uing  Script 

		
edu-gcp-bkt1


	Storage :
	
		File System Storage 
		
		Database Storage 
		
			MySQL
			
			
			SQL Services

	
		


~~~~~~~~~~~~~~~~~~~~~~~
Day 11 | 14th Sep. 2024
~~~~~~~~~~~~~~~~~~~~~~~		



	Kubernetes Installaion procedure - Open Source! 

		
		
		kubectl expose deployment hello-server --type=LoadBalancer --port 8080 –target-port 8080
		
		
	Infra-Structure Provisioning using Terraform ::::
	
		Deployment :
		
			Docker/Kubernetes 
		
		Infra-Structure :
		
			Terraform ::
			
			
			
		Terraform Architecture
		
			-	
			
		Terraform Working Model :
		
			- Identify Scope -> the target environment( GCP, AWS / Azure)
			
			- Write / Create Terraform script 
			
			- Terraform init							# Used to initlize the (VM)Resources
														Used to download the provider to project
														
			- Terraform plan							# To verifythe purity 
			# Used preview from whr to start the resting
			
			- Terrafor apply							# Used preview from whr to start the resting
			
			
		
			-- exit										-- Close all the produ
		Core Process and Components
		
		Hybrid Environments / Multi-Cloud Environment
		
		
		Infra-Structure :
		
			Deploy some Applications :
			
						- AWS / GCP / Azure - Cloud services
						
						- On-Prem Servers 

	Create some server using terrafrom 
	
	
	Working with Terraform

	1. Install Teraform
		Take care of underlyresource configurations:::
	2. pROCEDURCES:::

	
		- Install terrform in the local windows machine 
			- Setup the environment variable of remote machine for Terraform 
			
			https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli
			
			from the installation page, select manual installation tab --. Choose appropriate package

			download Windows - AMD64 version 
			
			*zip 
			
			extract the zip file 
			
			create environment vaiables using PATH exec file.
			
			
			
			
			
	
		
		
		
				VM1(terraform)
					- provision vm1,2,3,4,5,6,7,8,..........
				
				
				

			
			- Identify Scope -> the target environment( GCP, AWS / Azure)
			
			- Write / Create Terraform script 
			
			- Terraform init							# Used to initlize the (VM)Resources
														Used to creae the respurceed
			- Terraform plan							# To verifythe purity 
			# Used preview from whr to start the resting
			
			- Terrafor apply							# Used preview from whr to start the resting
		
		
		

		Using Terraform:

			- Add/Create the resource 						=====>			+
	

			- Delete/Destroy delete the required filesl		=====>			=
			
			
			- Modify/Update the resource 					=====>			/			


			- Create the resource 		=====>			+



provider "aws" {
  region     = "ap-south-1"
  access_key = "A24F"
  secret_key = "3+D"
}

# Create AWS Instance

resource "aws_instance" "tcsinstance1" {
  
  ami           = "ami-0e53db6fd757e38c7"
  instance_type = "t2.micro"
  key_name      = "may20-keypair"

  tags = {
    Name = "TCS-TestInstance1"
  }
}
























# Create AWS Instance

resource "aws_instanceeee" "app_server2" {
  ami           = "ami-09f7fbc41963e146f"
  instance_type = "t2.micro"
  key_name      = "loksaieta123"

  tags = {
    Name = "TerraformDemoServer2"
  }
}



+ => Add new resource
~ => update any existing resource
- => Delete any existing resource


terraform init

terraform plan

terraform apply

terraform destroy

terraform state list

terraform apply -auto-approve



*****************************************************************************************




Install Terraform --> Local Windows Machine!!!

Use Command prompt to run Terraform commands like : terraform init, terraform plan, terraform apply, etc..

Create the Config file ?

Visual Studio Code  to create or develop Terraform Config files! i.e., *.tf files 






provider "aws" {
  region     = "ap-south-1"
  access_key = "AKF"
  secret_key = "3i+D"
}


# Create VPC

resource "aws_vpc" "myvpc9" {
  cidr_block       = "10.0.0.0/16"
  instance_tenancy = "default"

  tags = {
    Name = "myvpc9"
  }
}

# Create Subnet 

resource "aws_subnet" "mysubnet9" {
  vpc_id     = aws_vpc.myvpc9.id
  cidr_block = "10.0.1.0/24"

  tags = {
    Name = "mysubnet9"
  }
}

# Internet Gateway

resource "aws_internet_gateway" "mygw9" {
  vpc_id = aws_vpc.myvpc9.id

  tags = {
    Name = "mygw9"
  }
}

# Route Table

resource "aws_route_table" "myrt9" {
  vpc_id = aws_vpc.myvpc9.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.mygw9.id
  }

  tags = {
    Name = "myrt9"
  }
}

# Route Table Association

resource "aws_route_table_association" "myrta9" {
  subnet_id      = aws_subnet.mysubnet9.id
  route_table_id = aws_route_table.myrt9.id
}

# Security Groups

resource "aws_security_group" "mysg9" {
  name        = "mysg9"
  description = "Allow inbound traffic"
  vpc_id      = aws_vpc.myvpc9.id

  ingress {
    description      = "HTTP"
    from_port        = 80
    to_port          = 80
    protocol         = "tcp"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  ingress {
    description      = "SSH"
    from_port        = 22
    to_port          = 22
    protocol         = "tcp"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  egress {
    from_port        = 0
    to_port          = 0
    protocol         = "-1"
    cidr_blocks      = ["0.0.0.0/0"]
    ipv6_cidr_blocks = ["::/0"]
  }

  tags = {
    Name = "mysg9"
  }
}

# Create Instance

resource "aws_instance" "instance9" {
  ami           = "ami-0f58b397bc5c1f2e8"
  instance_type = "t2.micro"
  associate_public_ip_address = true
  subnet_id = aws_subnet.mysubnet9.id
  vpc_security_group_ids = [aws_security_group.mysg9.id]
  key_name = "awskey-124"

  tags = {
    Name = "Dummy_Server0"
  }
}



~~~~~~~~~~~~~~~~~~~~~~~
Day 12 | 15th Sep. 2024
~~~~~~~~~~~~~~~~~~~~~~~	


	UseCases - GCP AI & ML Services 
	
		GCP - AI & Machine Languages Service!
		
		
		GCP :
		
			Gen App Builder
	
			Gen App Builder is a powerful tool that helps developers with no machine learning experience create enterprise grade generative AI apps. This tool offers a no code approach, enabling developers to build high quality experiences in minutes or hours.

			Time Series Database - That maintains the metrics of Deployments and the servers 

			GCP Vertex AI 
			
			Is a managed machine learning (ML) platform that lets developers, data scientists, and analysts build, train, and deploy machine learning models at scale. It's essentially the evolution and unification of various AI and ML products like AI Platform Training, AI
			
			
			Big Query :: 
			
			Machine Learning!
			
			
			AI vs Gen AI :::
			
			Data mining!
			
			Data Analysis!
			

			Data Analyst / Gen AI / ML 
			
			Speach Recognization 
			

			AI/ML Observability ::

				Meant for complex and crucial system.
					Infra-Structure
					Application Health check
					
					
			Infra-Structure Monitoring!		--> 1000s of Servers to be monitored!
			
				CPU / Memory Utilization 
					- Threshold Limit 
						80% -- Alert the Users 

							
				Process Automation Script!
				
					 python/ruby/
				
				
				
